{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e56c2ef",
   "metadata": {},
   "source": [
    "# 뉴스 카테고리 다중분류 프로젝트 (Vocab = 5000)\n",
    "#### 주제\n",
    "- Vocabulary Size 변경해서 시도해보기\n",
    "    1. 모든 단어 사용\n",
    "    2. 빈도수 상위 5000개의 단어만 사용\n",
    "    3. 직접 단어 개수 설정해서 사용 \n",
    "- 모델 3가지 이상 사용: SVC, LinearRegression, RandomForest, Voting\n",
    "    - RNN, 1-D CNN 등 딥러닝 모델 중 하나 선택해서 머신러닝과 결과 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d483aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "415527ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35f9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d4fe4",
   "metadata": {},
   "source": [
    "# 1.모든 단어 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9affc",
   "metadata": {},
   "source": [
    "## 1-1. 데이터 로드 및 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d04830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71acc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(x_train, y_train, x_test, y_test):\n",
    "    # 훈련 및 테스트 샘플 수 확인\n",
    "    print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "    print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "    \n",
    "    # 클래스 수 확인\n",
    "    num_classes = max(y_train) + 1\n",
    "    print('클래스의 수 : {}'.format(num_classes))\n",
    "    \n",
    "    # 훈련 데이터 최대 길이 및 평균 길이 확인\n",
    "    print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "    print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.hist([len(s) for s in x_train], bins=50)\n",
    "    plt.xlabel('length of samples')\n",
    "    plt.ylabel('number of samples')\n",
    "    plt.title(\"Length Distribution\")\n",
    "    \n",
    "    # 각 클래스 빈도수 확인\n",
    "    plt.subplot(212)\n",
    "    sns.countplot(x=y_train)\n",
    "    plt.title(\"Frequency of classes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa928c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_data(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fc00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(x_train, x_test):\n",
    "    # vocab 만들기\n",
    "    word_index = reuters.get_word_index(path = \"reuters_word_index.json\")\n",
    "    index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
    "    for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "        index_to_word[index] = token\n",
    "    \n",
    "    # index -> 원문 text 복원하기\n",
    "    x_train_decoded = []\n",
    "    for i in range(len(x_train)):\n",
    "        t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "        x_train_decoded.append(t)\n",
    "    \n",
    "    x_test_decoded = []\n",
    "    for i in range(len(x_test)):\n",
    "        t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "        x_test_decoded.append(t)\n",
    "    \n",
    "    dtmvector = CountVectorizer()\n",
    "    x_train_dtm = dtmvector.fit_transform(x_train_decoded)\n",
    "    x_test_dtm = dtmvector.transform(x_test_decoded)\n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "    x_test_tfidf = tfidf_transformer.transform(x_test_dtm)\n",
    "    \n",
    "    return x_train_tfidf, x_test_tfidf, x_train_decoded, x_test_decoded, word_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5676acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, x_train_decoded, x_test_decoded, word_index, index_to_word = vectorize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2d8f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 4867)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6e3981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246, 4867)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc93355",
   "metadata": {},
   "source": [
    "## 1-2. 머신러닝 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88786519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84064e8",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f52bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time for logistic regression: 536.41 초\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(C=10000, penalty = \"l2\", max_iter = 3000)\n",
    "lr.fit(x_train_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "learning_time_lr = end_time - start_time \n",
    "\n",
    "print(f\"training time for logistic regression:{learning_time_lr: .2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "603df4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.8036509349955476\n",
      "f1-score: 0.7985602317931111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.73      0.77      0.75       105\n",
      "           2       0.76      0.80      0.78        20\n",
      "           3       0.90      0.93      0.91       813\n",
      "           4       0.80      0.86      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.66      0.71      0.68        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.89      0.83      0.86        30\n",
      "          11       0.64      0.73      0.69        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.63      0.65      0.64        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.75      0.33      0.46         9\n",
      "          16       0.70      0.75      0.73        99\n",
      "          17       0.80      0.67      0.73        12\n",
      "          18       0.87      0.65      0.74        20\n",
      "          19       0.69      0.68      0.68       133\n",
      "          20       0.57      0.50      0.53        70\n",
      "          21       0.72      0.85      0.78        27\n",
      "          22       1.00      0.29      0.44         7\n",
      "          23       0.64      0.75      0.69        12\n",
      "          24       0.67      0.53      0.59        19\n",
      "          25       0.87      0.65      0.74        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.40      0.40      0.40        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       1.00      0.58      0.74        12\n",
      "          31       0.80      0.62      0.70        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.80      0.57      0.67         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.43      0.27      0.33        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       0.60      0.30      0.40        10\n",
      "          41       0.75      0.38      0.50         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.80      2246\n",
      "   macro avg       0.76      0.61      0.65      2246\n",
      "weighted avg       0.80      0.80      0.80      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(x_test_tfidf)\n",
    "acc_lr = accuracy_score(y_test, predicted)\n",
    "f1_lr = f1_score(y_test, predicted, average = 'weighted')\n",
    "print(\"정확도: \", acc_lr)\n",
    "print(\"f1-score:\", f1_lr)\n",
    "print(classification_report(y_test, predicted, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ce75d",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22098158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time for RandomForest: 1.29 초\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(n_estimators = 5, random_state = 0)\n",
    "rf.fit(x_train_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "learning_time_rf = end_time - start_time \n",
    "\n",
    "print(f\"training time for RandomForest:{learning_time_rf: .2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22074c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n",
      "f1-score: 0.6770217603524399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.33        12\n",
      "           1       0.42      0.78      0.55       105\n",
      "           2       0.44      0.35      0.39        20\n",
      "           3       0.84      0.90      0.87       813\n",
      "           4       0.68      0.84      0.75       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.43      0.57        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.59      0.53      0.56        38\n",
      "           9       0.71      0.40      0.51        25\n",
      "          10       0.89      0.53      0.67        30\n",
      "          11       0.57      0.69      0.62        83\n",
      "          12       0.33      0.15      0.21        13\n",
      "          13       0.46      0.32      0.38        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.11      0.20         9\n",
      "          16       0.70      0.67      0.68        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.60      0.45      0.51        20\n",
      "          19       0.62      0.64      0.63       133\n",
      "          20       0.46      0.33      0.38        70\n",
      "          21       0.65      0.41      0.50        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.75      0.25      0.38        12\n",
      "          24       0.33      0.05      0.09        19\n",
      "          25       0.87      0.42      0.57        31\n",
      "          26       1.00      0.12      0.22         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.33      0.25      0.29         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.30      0.46        10\n",
      "          33       1.00      0.20      0.33         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.33      0.09      0.14        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.25      0.12      0.17         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       1.00      0.33      0.50         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.70      2246\n",
      "   macro avg       0.54      0.31      0.36      2246\n",
      "weighted avg       0.69      0.70      0.68      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = rf.predict(x_test_tfidf)\n",
    "acc_rf = accuracy_score(y_test, predicted)\n",
    "f1_rf = f1_score(y_test, predicted, average = 'weighted')\n",
    "print(\"정확도:\", acc_rf) \n",
    "print(\"f1-score:\", f1_rf)\n",
    "print(classification_report(y_test, predicted, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767c033",
   "metadata": {},
   "source": [
    "### CalibratedClassifierCV + linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44d3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time for CalibratedSVC: 462.52 초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "start_time = time.time()\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "calibrated_model = CalibratedClassifierCV(lsvc, cv = 5)\n",
    "calibrated_model.fit(x_train_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "learning_time_ccsvc = end_time - start_time\n",
    "\n",
    "print(f\"training time for CalibratedSVC:{learning_time_ccsvc: .2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "068416e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.794746215494212\n",
      "f1-score:  0.7840837414249962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.76      0.78      0.77       105\n",
      "           2       0.79      0.75      0.77        20\n",
      "           3       0.88      0.94      0.91       813\n",
      "           4       0.78      0.87      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.69      0.66      0.68        38\n",
      "           9       0.84      0.84      0.84        25\n",
      "          10       0.92      0.80      0.86        30\n",
      "          11       0.66      0.73      0.69        83\n",
      "          12       0.50      0.31      0.38        13\n",
      "          13       0.62      0.57      0.59        37\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.67      0.22      0.33         9\n",
      "          16       0.70      0.72      0.71        99\n",
      "          17       1.00      0.50      0.67        12\n",
      "          18       0.92      0.60      0.73        20\n",
      "          19       0.68      0.71      0.69       133\n",
      "          20       0.62      0.46      0.52        70\n",
      "          21       0.66      0.78      0.71        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.70      0.58      0.64        12\n",
      "          24       0.71      0.53      0.61        19\n",
      "          25       0.82      0.58      0.68        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.43      0.30      0.35        10\n",
      "          29       0.20      0.25      0.22         4\n",
      "          30       1.00      0.33      0.50        12\n",
      "          31       0.86      0.46      0.60        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       1.00      0.29      0.44         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.80      0.36      0.50        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.75      0.38      0.50         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.79      2246\n",
      "   macro avg       0.78      0.54      0.60      2246\n",
      "weighted avg       0.79      0.79      0.78      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = calibrated_model.predict(x_test_tfidf)\n",
    "acc_ccsvc = accuracy_score(y_test, predicted)\n",
    "f1_ccsv = f1_score(y_test, predicted, average = 'weighted')\n",
    "print(\"정확도: \", acc_ccsvc)\n",
    "print(\"f1-score: \", f1_ccsv)\n",
    "print(classification_report(y_test, predicted, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23032596",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23e6b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time for SVC: 1546.97 초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators = [\n",
    "    ('lr', lr), ('rf', rf), ('ccsvc', calibrated_model)],\n",
    "    voting = 'soft'\n",
    ")\n",
    "voting_classifier.fit(x_train_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "learning_time_voting = end_time - start_time\n",
    "\n",
    "print(f\"training time for SVC:{learning_time_voting: .2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72e12070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.8076580587711487\n",
      "f1-score:  0.7997169279799828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.70      0.77      0.74       105\n",
      "           2       0.71      0.75      0.73        20\n",
      "           3       0.90      0.93      0.92       813\n",
      "           4       0.79      0.88      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.70      0.74      0.72        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.92      0.80      0.86        30\n",
      "          11       0.66      0.73      0.69        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.65      0.65      0.65        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.67      0.22      0.33         9\n",
      "          16       0.71      0.76      0.74        99\n",
      "          17       1.00      0.58      0.74        12\n",
      "          18       0.87      0.65      0.74        20\n",
      "          19       0.69      0.73      0.71       133\n",
      "          20       0.64      0.49      0.55        70\n",
      "          21       0.76      0.81      0.79        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.64      0.75      0.69        12\n",
      "          24       0.67      0.53      0.59        19\n",
      "          25       0.87      0.65      0.74        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.50      0.30      0.37        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       1.00      0.58      0.74        12\n",
      "          31       0.88      0.54      0.67        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.67      0.29      0.40         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.50      0.36      0.42        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.75      0.38      0.50         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.77      0.58      0.63      2246\n",
      "weighted avg       0.81      0.81      0.80      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(x_test_tfidf)\n",
    "acc_voting = accuracy_score(y_test, predicted)\n",
    "f1_voting = f1_score(y_test, predicted, average = 'weighted')\n",
    "print(\"정확도: \", acc_voting)\n",
    "print(\"f1-score: \", f1_voting)\n",
    "print(classification_report(y_test, predicted, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae511ba8",
   "metadata": {},
   "source": [
    "### DeepLearning - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b22e6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 추가\n",
    "maxlen = 440\n",
    "\n",
    "word_to_index = {word:index for index, word in index_to_word.items()}\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, value = word_to_index[\"<pad>\"], padding = 'pre', maxlen = maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, value = word_to_index[\"<pad>\"], padding = 'pre', maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2e53bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7185, 440), (7185,), (1797, 440), (1797,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test, val 나누기 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_partial, x_val, y_train_partial, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 2024)\n",
    "x_train_partial.shape, y_train_partial.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09574433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7081590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         640000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 782,830\n",
      "Trainable params: 782,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "vocab_size = 5000\n",
    "word_vector_dim = 128\n",
    "\n",
    "model_rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape = (None, )),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(64, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(46, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b5e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"best_model_rnn.keras\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "167f93fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 207ms/step - loss: 3.2994 - accuracy: 0.3499 - val_loss: 2.6098 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.35893, saving model to best_model_rnn.keras\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 2.5199 - accuracy: 0.3324 - val_loss: 2.4518 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.35893\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 2.4319 - accuracy: 0.3499 - val_loss: 2.4196 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.35893\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 2.4048 - accuracy: 0.3499 - val_loss: 2.3882 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.35893\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 2.3618 - accuracy: 0.3499 - val_loss: 2.2409 - val_accuracy: 0.3589\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.35893\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 2.1293 - accuracy: 0.3978 - val_loss: 2.0991 - val_accuracy: 0.3790\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.35893 to 0.37896, saving model to best_model_rnn.keras\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.9447 - accuracy: 0.4465 - val_loss: 1.8719 - val_accuracy: 0.4908\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.37896 to 0.49082, saving model to best_model_rnn.keras\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.7513 - accuracy: 0.5255 - val_loss: 1.7784 - val_accuracy: 0.5109\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.49082 to 0.51085, saving model to best_model_rnn.keras\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.6896 - accuracy: 0.5321 - val_loss: 1.8448 - val_accuracy: 0.4847\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.51085\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.7023 - accuracy: 0.5272 - val_loss: 1.8572 - val_accuracy: 0.5047\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.51085\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.6680 - accuracy: 0.5464 - val_loss: 1.7354 - val_accuracy: 0.5320\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.51085 to 0.53200, saving model to best_model_rnn.keras\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.5756 - accuracy: 0.5708 - val_loss: 1.7017 - val_accuracy: 0.5392\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.53200 to 0.53923, saving model to best_model_rnn.keras\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.5147 - accuracy: 0.5936 - val_loss: 1.6813 - val_accuracy: 0.5643\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.53923 to 0.56427, saving model to best_model_rnn.keras\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.4604 - accuracy: 0.6043 - val_loss: 1.6844 - val_accuracy: 0.5620\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.56427\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.4185 - accuracy: 0.6164 - val_loss: 1.6402 - val_accuracy: 0.5760\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.56427 to 0.57596, saving model to best_model_rnn.keras\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.3601 - accuracy: 0.6298 - val_loss: 1.8235 - val_accuracy: 0.5237\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.57596\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 1.4099 - accuracy: 0.6128 - val_loss: 1.6343 - val_accuracy: 0.5737\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.57596\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.3089 - accuracy: 0.6443 - val_loss: 1.6342 - val_accuracy: 0.5943\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.57596 to 0.59432, saving model to best_model_rnn.keras\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.2496 - accuracy: 0.6610 - val_loss: 1.6153 - val_accuracy: 0.5915\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59432\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 1.1917 - accuracy: 0.6701 - val_loss: 1.6928 - val_accuracy: 0.5654\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59432\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.1734 - accuracy: 0.6811 - val_loss: 1.6493 - val_accuracy: 0.5860\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59432\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.1506 - accuracy: 0.6767 - val_loss: 1.5919 - val_accuracy: 0.6077\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.59432 to 0.60768, saving model to best_model_rnn.keras\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.0759 - accuracy: 0.6949 - val_loss: 1.5853 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.60768 to 0.61380, saving model to best_model_rnn.keras\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 1.0033 - accuracy: 0.7278 - val_loss: 1.5620 - val_accuracy: 0.6311\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.61380 to 0.63105, saving model to best_model_rnn.keras\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.9506 - accuracy: 0.7382 - val_loss: 1.7070 - val_accuracy: 0.6149\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.63105\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.9591 - accuracy: 0.7257 - val_loss: 1.6170 - val_accuracy: 0.6227\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.63105\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.8749 - accuracy: 0.7523 - val_loss: 1.6617 - val_accuracy: 0.6266\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.63105\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.8421 - accuracy: 0.7602 - val_loss: 1.6704 - val_accuracy: 0.6361\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.63105 to 0.63606, saving model to best_model_rnn.keras\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.8175 - accuracy: 0.7678 - val_loss: 1.6243 - val_accuracy: 0.6439\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.63606 to 0.64385, saving model to best_model_rnn.keras\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.7567 - accuracy: 0.7769 - val_loss: 1.6604 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64385\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.7260 - accuracy: 0.7916 - val_loss: 1.6497 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.64385 to 0.65331, saving model to best_model_rnn.keras\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.6882 - accuracy: 0.8018 - val_loss: 1.7379 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.65331 to 0.65665, saving model to best_model_rnn.keras\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.6658 - accuracy: 0.8100 - val_loss: 1.7246 - val_accuracy: 0.6311\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65665\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.6315 - accuracy: 0.8263 - val_loss: 1.6786 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.65665 to 0.65888, saving model to best_model_rnn.keras\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.5905 - accuracy: 0.8358 - val_loss: 1.7369 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65888\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.5540 - accuracy: 0.8484 - val_loss: 1.8414 - val_accuracy: 0.6349\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.65888\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.6961 - accuracy: 0.7986 - val_loss: 1.7229 - val_accuracy: 0.6561\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65888\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.6416 - accuracy: 0.8149 - val_loss: 1.7438 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65888\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.5684 - accuracy: 0.8437 - val_loss: 1.7466 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65888\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.4847 - accuracy: 0.8692 - val_loss: 1.7740 - val_accuracy: 0.6555\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65888\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.4441 - accuracy: 0.8788 - val_loss: 1.8567 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65888\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.4111 - accuracy: 0.8903 - val_loss: 1.8640 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.65888\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.3854 - accuracy: 0.9030 - val_loss: 1.8767 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65888\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.3782 - accuracy: 0.9016 - val_loss: 1.9322 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65888\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.3508 - accuracy: 0.9129 - val_loss: 1.9196 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.65888 to 0.66055, saving model to best_model_rnn.keras\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.3594 - accuracy: 0.9069 - val_loss: 1.9785 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66055\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.3179 - accuracy: 0.9184 - val_loss: 2.0417 - val_accuracy: 0.6450\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66055\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.3391 - accuracy: 0.9097 - val_loss: 2.0622 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66055\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 0.2997 - accuracy: 0.9254 - val_loss: 2.0445 - val_accuracy: 0.6511\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.66055\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.2816 - accuracy: 0.9297 - val_loss: 2.0603 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66055\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.2594 - accuracy: 0.9396 - val_loss: 2.1129 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.66055\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.2610 - accuracy: 0.9361 - val_loss: 2.1195 - val_accuracy: 0.6555\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.66055\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.2519 - accuracy: 0.9378 - val_loss: 2.1237 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.66055 to 0.66333, saving model to best_model_rnn.keras\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.2643 - accuracy: 0.9338 - val_loss: 2.1173 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.66333\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.2311 - accuracy: 0.9421 - val_loss: 2.2668 - val_accuracy: 0.6472\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.66333\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.2389 - accuracy: 0.9374 - val_loss: 2.1565 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.66333\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.2159 - accuracy: 0.9463 - val_loss: 2.1686 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.66333\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.2056 - accuracy: 0.9505 - val_loss: 2.2358 - val_accuracy: 0.6439\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.66333\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1991 - accuracy: 0.9503 - val_loss: 2.2204 - val_accuracy: 0.6489\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.66333\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1825 - accuracy: 0.9557 - val_loss: 2.2369 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.66333\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1710 - accuracy: 0.9574 - val_loss: 2.2580 - val_accuracy: 0.6611\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.66333\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1796 - accuracy: 0.9550 - val_loss: 2.2342 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.66333\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1692 - accuracy: 0.9576 - val_loss: 2.2807 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.66333\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1767 - accuracy: 0.9570 - val_loss: 2.2814 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.66333\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.1763 - accuracy: 0.9539 - val_loss: 2.3112 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.66333 to 0.66667, saving model to best_model_rnn.keras\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1701 - accuracy: 0.9578 - val_loss: 2.2924 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.66667\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1549 - accuracy: 0.9594 - val_loss: 2.3403 - val_accuracy: 0.6555\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.66667\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1489 - accuracy: 0.9612 - val_loss: 2.3950 - val_accuracy: 0.6566\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.66667\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1435 - accuracy: 0.9627 - val_loss: 2.3495 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.66667\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.2227 - accuracy: 0.9400 - val_loss: 2.3609 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.66667 to 0.66889, saving model to best_model_rnn.keras\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.1965 - accuracy: 0.9481 - val_loss: 2.3254 - val_accuracy: 0.6561\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.66889\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.1690 - accuracy: 0.9562 - val_loss: 2.3476 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.66889\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.1426 - accuracy: 0.9612 - val_loss: 2.3751 - val_accuracy: 0.6522\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.66889\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.1296 - accuracy: 0.9644 - val_loss: 2.3514 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.66889\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.1203 - accuracy: 0.9653 - val_loss: 2.3846 - val_accuracy: 0.6561\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.66889\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 1s 100ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 2.4362 - val_accuracy: 0.6611\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.66889\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.1088 - accuracy: 0.9649 - val_loss: 2.4530 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.66889\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1116 - accuracy: 0.9663 - val_loss: 2.4404 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.66889\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1074 - accuracy: 0.9672 - val_loss: 2.4666 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.66889\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1027 - accuracy: 0.9655 - val_loss: 2.4922 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.66889\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.1023 - accuracy: 0.9652 - val_loss: 2.5134 - val_accuracy: 0.6561\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.66889\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.0995 - accuracy: 0.9694 - val_loss: 2.5305 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.66889\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.1196 - accuracy: 0.9620 - val_loss: 2.6024 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.66889\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.1320 - accuracy: 0.9580 - val_loss: 2.6363 - val_accuracy: 0.6511\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.66889\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.1231 - accuracy: 0.9624 - val_loss: 2.6686 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.66889\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.4503 - accuracy: 0.8763 - val_loss: 2.5431 - val_accuracy: 0.6127\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.66889\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.3796 - accuracy: 0.8842 - val_loss: 2.2899 - val_accuracy: 0.6561\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.66889\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.2210 - accuracy: 0.9329 - val_loss: 2.3480 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.66889\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1741 - accuracy: 0.9500 - val_loss: 2.4023 - val_accuracy: 0.6522\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.66889\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.1433 - accuracy: 0.9594 - val_loss: 2.4136 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.66889\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1276 - accuracy: 0.9610 - val_loss: 2.5054 - val_accuracy: 0.6450\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.66889\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1356 - accuracy: 0.9594 - val_loss: 2.5299 - val_accuracy: 0.6594\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.66889\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1154 - accuracy: 0.9646 - val_loss: 2.5400 - val_accuracy: 0.6578\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.66889\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.1044 - accuracy: 0.9641 - val_loss: 2.5480 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.66889\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0972 - accuracy: 0.9660 - val_loss: 2.6084 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.66889\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0941 - accuracy: 0.9660 - val_loss: 2.6141 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.66889\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1071 - accuracy: 0.9634 - val_loss: 2.6710 - val_accuracy: 0.6472\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.66889\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 0.0950 - accuracy: 0.9685 - val_loss: 2.6954 - val_accuracy: 0.6377\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.66889\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.1320 - accuracy: 0.9564 - val_loss: 2.6702 - val_accuracy: 0.6639\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.66889\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0997 - accuracy: 0.9659 - val_loss: 2.6762 - val_accuracy: 0.6511\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.66889\n",
      "training time for rnn: 171.64 초\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_rnn.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "history_rnn = model_rnn.fit(x_train_partial, \n",
    "                            y_train_partial, \n",
    "                            epochs = 100, \n",
    "                            batch_size = 512,\n",
    "                            validation_data = (x_val, y_val),\n",
    "                            callbacks = [checkpoint])\n",
    "end_time = time.time()\n",
    "learning_time_rnn = end_time - start_time\n",
    "print(f\"training time for rnn:{learning_time_rnn: .2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c35da3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 2s - loss: 2.7957 - accuracy: 0.6380\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_rnn = load_model(\"best_model_rnn.keras\")\n",
    "results_rnn = model_rnn.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b368768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.42      0.36        12\n",
      "           1       0.46      0.48      0.47       105\n",
      "           2       0.26      0.45      0.33        20\n",
      "           3       0.87      0.91      0.89       813\n",
      "           4       0.78      0.79      0.78       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.62      0.36      0.45        14\n",
      "           7       0.25      0.33      0.29         3\n",
      "           8       0.44      0.29      0.35        38\n",
      "           9       0.35      0.24      0.29        25\n",
      "          10       0.35      0.23      0.28        30\n",
      "          11       0.37      0.36      0.36        83\n",
      "          12       0.33      0.23      0.27        13\n",
      "          13       0.22      0.22      0.22        37\n",
      "          14       0.20      0.50      0.29         2\n",
      "          15       0.10      0.11      0.11         9\n",
      "          16       0.35      0.56      0.43        99\n",
      "          17       0.08      0.08      0.08        12\n",
      "          18       0.23      0.15      0.18        20\n",
      "          19       0.55      0.43      0.48       133\n",
      "          20       0.43      0.34      0.38        70\n",
      "          21       0.36      0.30      0.33        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.06      0.08      0.07        12\n",
      "          24       0.15      0.11      0.12        19\n",
      "          25       0.57      0.26      0.36        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.25      0.25      0.25        12\n",
      "          31       0.29      0.15      0.20        13\n",
      "          32       0.22      0.20      0.21        10\n",
      "          33       0.57      0.80      0.67         5\n",
      "          34       0.22      0.29      0.25         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.07      0.09      0.08        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.40      0.20      0.27        10\n",
      "          41       0.12      0.12      0.12         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.43      0.50      0.46         6\n",
      "          44       0.33      0.20      0.25         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.64      2246\n",
      "   macro avg       0.26      0.26      0.25      2246\n",
      "weighted avg       0.63      0.64      0.63      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model_rnn.predict(x_test)\n",
    "predicted_classes = np.argmax(predicted, axis = 1)\n",
    "print(classification_report(y_test, predicted_classes, zero_division = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
