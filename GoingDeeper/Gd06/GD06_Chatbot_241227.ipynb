{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239410f0",
   "metadata": {},
   "source": [
    "# Project: 멋진 챗봇 만들기\n",
    "\n",
    "**루브릭**\n",
    "<img width=\"630\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0f8bf706-f619-429c-a9b4-21b4fb261aa6\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb94b0a",
   "metadata": {},
   "source": [
    "# 0. 필요 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc42464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc419f0",
   "metadata": {},
   "source": [
    "# 1. 데이터 다운로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73037299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "data = pd.read_csv(data_url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de939fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a38254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.DataFrame(data['Q'])\n",
    "answers = pd.DataFrame(data['A'])\n",
    "\n",
    "len(questions), len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509b411",
   "metadata": {},
   "source": [
    "# 2. 데이터 정제 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612d36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-zA-Z0-9가-힣?.!,]+\", \" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941985b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoNLPY mecab 사용\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086a84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Questions Dataset\n",
      "Min:  1\n",
      "Max:  32\n",
      "Avg:  7.020045673686882\n",
      "\n",
      "Answers Dataset\n",
      "Min:  1\n",
      "Max:  40\n",
      "Avg:  8.376554174067495\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토큰 길이 분포 확인하기\n",
    "mecab = Mecab()\n",
    "src_tokenized = [mecab.morphs(preprocess_sentence(sent)) for sent in questions['Q']]\n",
    "tgt_tokenized = [mecab.morphs(preprocess_sentence(sent)) for sent in answers['A']]\n",
    "\n",
    "src_token_len = [len(tokens) for tokens in src_tokenized]\n",
    "tgt_token_len = [len(tokens) for tokens in tgt_tokenized]\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Questions Dataset\")\n",
    "print(\"Min: \", np.min(src_token_len))\n",
    "print(\"Max: \", np.max(src_token_len))\n",
    "print(\"Avg: \", np.average(src_token_len))\n",
    "\n",
    "print(\"\\nAnswers Dataset\")\n",
    "print(\"Min: \", np.min(tgt_token_len))\n",
    "print(\"Max: \", np.max(tgt_token_len))\n",
    "print(\"Avg: \", np.average(tgt_token_len))\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "plt.figure(figsize = (8, 10))\n",
    "plt.subplot(211)\n",
    "plt.hist(src_token_len)\n",
    "plt.xlabel(\"token lengths\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Token Lengths of Questions Dataset\")   \n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(tgt_token_len)\n",
    "plt.xlabel(\"token lengths\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Token Lengths of Answers Dataset\")   \n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a90abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['건방져']\n",
      "['겁난다']\n",
      "['굿모닝']\n",
      "['단수']\n",
      "['더워']\n",
      "['무서워요']\n",
      "['미워']\n",
      "['미워한다']\n",
      "['반가워']\n",
      "['반가워']\n",
      "['배고파']\n",
      "['배고파']\n",
      "['배불러']\n",
      "['배불러']\n",
      "['비트코인']\n",
      "['속상해']\n",
      "['스트레스']\n",
      "['아파']\n",
      "['안녕']\n",
      "['야']\n",
      "['어머']\n",
      "['어머나']\n",
      "['에이씨']\n",
      "['오지마']\n",
      "['외로워']\n",
      "['외로워']\n",
      "['으악']\n",
      "['음']\n",
      "['응']\n",
      "['이놈']\n",
      "['잘래']\n",
      "['저기']\n",
      "['조심조심']\n",
      "['졸려']\n",
      "['추워']\n",
      "['코자']\n",
      "['콜록콜록']\n",
      "['허기져']\n",
      "['헉']\n",
      "['괴로워']\n",
      "['그리움']\n",
      "['기다림']\n",
      "['꿈']\n",
      "['나그네']\n",
      "['넋두리']\n",
      "['눈물']\n",
      "['답답증']\n",
      "['덤덤']\n",
      "['뜬금없이']\n",
      "['마무리']\n",
      "['멘붕']\n",
      "['무상']\n",
      "['무제']\n",
      "['미련']\n",
      "['미쳐']\n",
      "['바람']\n",
      "['받아들여야지']\n",
      "['변명']\n",
      "['분노']\n",
      "['불면증']\n",
      "['사진첩']\n",
      "['살아간다']\n",
      "['상념']\n",
      "['상처']\n",
      "['새벽']\n",
      "['술주정']\n",
      "['시련']\n",
      "['심심']\n",
      "['싱숭생숭']\n",
      "['쓰레기']\n",
      "['씁쓸']\n",
      "['아파']\n",
      "['야']\n",
      "['양다리']\n",
      "['어째서']\n",
      "['에휴']\n",
      "['연휴']\n",
      "['왜']\n",
      "['외로움']\n",
      "['외로워']\n",
      "['외로워']\n",
      "['외로워서']\n",
      "['으흠']\n",
      "['이별']\n",
      "['이혼']\n",
      "['인내']\n",
      "['인연']\n",
      "['자괴감']\n",
      "['잠수']\n",
      "['젠장']\n",
      "['주저리주저리']\n",
      "['증오']\n",
      "['지친다']\n",
      "['짝사랑']\n",
      "['착각']\n",
      "['첫눈']\n",
      "['최악']\n",
      "['침묵']\n",
      "['통증']\n",
      "['파혼']\n",
      "['핑계']\n",
      "['한숨']\n",
      "['헤어짐']\n",
      "['헤어짐']\n",
      "['혼자']\n",
      "['후']\n",
      "['후우']\n",
      "['후회']\n",
      "['휴']\n",
      "['흔적']\n",
      "['흠']\n",
      "['고백']\n"
     ]
    }
   ],
   "source": [
    "for length, tokens in zip(src_token_len, src_tokenized):\n",
    "    if length == 1:\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb070905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['킁킁']\n",
      "['킁킁']\n",
      "['킁킁']\n",
      "['꼬르륵']\n",
      "['꼬르륵']\n",
      "['네']\n",
      "['킁킁']\n",
      "['음']\n",
      "['네']\n",
      "['음']\n",
      "['토닥토닥']\n",
      "['사랑']\n",
      "['네']\n",
      "['네']\n",
      "['아이구']\n",
      "['휴우']\n",
      "['어머나']\n"
     ]
    }
   ],
   "source": [
    "for length, tokens in zip(tgt_token_len, tgt_tokenized):\n",
    "    if length == 1:\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc2e56",
   "metadata": {},
   "source": [
    "- 토큰 개수가 1개인 Question, Answer 출력했을 때, 노이즈가 많이 섞여있는 듯 함...\n",
    "- 일단은 다 포함하는 것으로... \n",
    "- max_len 값도 우선 40까지 모두 포함하기로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a3c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 토큰화, 중복데이터 제거 \n",
    "\n",
    "def build_corpus(src_data, tgt_data):\n",
    "    \n",
    "    # 텍스트 전처리\n",
    "    src_data['Q'] = src_data['Q'].apply(preprocess_sentence)\n",
    "    tgt_data['A'] = tgt_data['A'].apply(preprocess_sentence)\n",
    "    \n",
    "    # 중복 Index 확인\n",
    "    dup_index = []\n",
    "    src_dup_idx = [idx for idx in src_data[src_data['Q'].duplicated()].index]\n",
    "    print(\"len of src_dup_idx: \", len(src_dup_idx))\n",
    "    tgt_dup_idx = [idx for idx in tgt_data[tgt_data['A'].duplicated()].index]\n",
    "    print(\"len of tgt_dup_idx: \", len(tgt_dup_idx))\n",
    "    src_dup_idx.extend(tgt_dup_idx)\n",
    "    dup_idx = list(set(src_dup_idx))\n",
    "    print(\"len of dup_idx: \", len(dup_idx))\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    # 중복 데이터 제거\n",
    "    filtered_src_data = src_data.drop(index = dup_idx)\n",
    "    filtered_tgt_data = tgt_data.drop(index = dup_idx)\n",
    "    print(\"Original src_data length: \", len(src_data))\n",
    "    print(\"Filtered src_data length: \", len(filtered_src_data))\n",
    "    print(\"Original tgt_data length: \", len(tgt_data))\n",
    "    print(\"Filtered tgt_data length: \", len(filtered_tgt_data))\n",
    "    \n",
    "    # 토큰화\n",
    "    src_tokenized = [mecab.morphs(sent) for sent in filtered_src_data['Q']]\n",
    "    tgt_tokenized = [mecab.morphs(sent) for sent in filtered_tgt_data['A']]\n",
    "    \n",
    "    return src_tokenized, tgt_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ba77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of src_dup_idx:  161\n",
      "len of tgt_dup_idx:  4044\n",
      "len of dup_idx:  4111\n",
      "--------------------------------------\n",
      "Original src_data length:  11823\n",
      "Filtered src_data length:  7712\n",
      "Original tgt_data length:  11823\n",
      "Filtered tgt_data length:  7712\n"
     ]
    }
   ],
   "source": [
    "que_corpus, ans_corpus = build_corpus(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055d4e6",
   "metadata": {},
   "source": [
    "# 3. Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23209135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     |████████████████████████████████| 23.4 MB 4.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=24328218 sha256=9694ba4443647649782bfaa5cbff3cb041af1a300ac2e13ba2385c9f2442cb92\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed gensim-3.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# gensim 버전 문제 발생 4.x -> 3.x 버전으로 다운그레이드\n",
    "!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd7f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('고양이', 0.7290452718734741),\n",
       " ('거위', 0.7185635566711426),\n",
       " ('토끼', 0.7056223154067993),\n",
       " ('멧돼지', 0.6950401067733765),\n",
       " ('엄마', 0.6934334635734558),\n",
       " ('난쟁이', 0.6806551218032837),\n",
       " ('한마리', 0.6770296096801758),\n",
       " ('아가씨', 0.6750352382659912),\n",
       " ('아빠', 0.6729634404182434),\n",
       " ('목걸이', 0.6512460708618164)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model_path = \"ko.bin\"\n",
    "ko_model = gensim.models.Word2Vec.load(model_path)\n",
    "ko_model.wv.most_similar(\"강아지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e60accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(aug_tokens, ko_model):\n",
    "    \n",
    "    # 숫자가 선택되는 경우 에러 발생하여 한글만 선택하도록 설정\n",
    "    candidate_tokens = [tok for tok in aug_tokens if re.match(r\"^[가-힣]+$\", tok)]\n",
    "    if not candidate_tokens:\n",
    "        return aug_tokens\n",
    "    \n",
    "    selected_tok = random.choice(candidate_tokens)\n",
    "    \n",
    "    result = []\n",
    "    for tok in aug_tokens:\n",
    "        if tok is selected_tok:\n",
    "            try:\n",
    "                \n",
    "                result.append(ko_model.wv.most_similar(tok)[0][0])\n",
    "            except KeyError:\n",
    "                result.append(tok)\n",
    "        else:\n",
    "            result.append(tok)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "459c536d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def corpus_augmentation(que_corpus, ans_corpus, ko_model):\n",
    "    que_corpus_result = []\n",
    "    ans_corpus_result = []\n",
    "    \n",
    "    # ans_corpus augmenation\n",
    "    ans_corpus_aug = [lexical_sub(tokens, ko_model) for tokens in ans_corpus]\n",
    "    \n",
    "    # que_corpus augmentation\n",
    "    que_corpus_aug = [lexical_sub(tokens, ko_model) for tokens in que_corpus]\n",
    "    \n",
    "    # consolidate augmentation results\n",
    "    que_corpus_result = que_corpus + que_corpus + que_corpus_aug\n",
    "    ans_corpus_result = ans_corpus + ans_corpus_aug + ans_corpus\n",
    "    \n",
    "    return que_corpus_result, ans_corpus_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05a75dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23136 23136\n"
     ]
    }
   ],
   "source": [
    "que_corpus, ans_corpus = corpus_augmentation(que_corpus, ans_corpus, ko_model)\n",
    "print(len(que_corpus), len(ans_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124dc48",
   "metadata": {},
   "source": [
    "# 4. 데이터 벡터화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ba504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '.', '<end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '.', '<end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', '<end>'],\n",
       " ['<start>', '눈살', '이', '찌푸려', '지', '죠', '.', '<end>'],\n",
       " ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '.', '<end>']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_start_end_tokens(tokens):\n",
    "    return ['<start>'] + tokens + [\"<end>\"]\n",
    "\n",
    "ans_corpus = [add_start_end_tokens(tokens) for tokens in ans_corpus]\n",
    "ans_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32654731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2204, 218, 3605, 108]\n",
      "[3, 282, 9, 142, 9, 42, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 20000\n",
    "\n",
    "# tokenizer 생성\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<unk>\")\n",
    "tokenizer.fit_on_texts(que_corpus + ans_corpus)\n",
    "\n",
    "# 정수 인코딩\n",
    "que_corpus_encoded = tokenizer.texts_to_sequences(que_corpus)\n",
    "ans_corpus_encoded = tokenizer.texts_to_sequences(ans_corpus)\n",
    "\n",
    "print(que_corpus_encoded[0])\n",
    "print(ans_corpus_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "514903d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95479c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 처리하기\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 40\n",
    "enc_train = pad_sequences(que_corpus_encoded, maxlen = max_len, padding = \"post\", value = 0)\n",
    "dec_train = pad_sequences(ans_corpus_encoded, maxlen = max_len, padding = \"post\", value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7f2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 나누기\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd8751",
   "metadata": {},
   "source": [
    "# 5. 훈련하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59dba0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99d25ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "156fedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84bb9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37e82771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28d0f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41c8114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5a50c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34c029d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "403b4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "n_layers = 6\n",
    "d_model = 256\n",
    "n_heads = 8\n",
    "d_ff = 1024\n",
    "pos_len = max_len\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3187999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 하이퍼파라미터로 Transformer 인스턴스 생성\n",
    "transformer = Transformer(\n",
    "    n_layers=n_layers,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    d_ff=d_ff,\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    pos_len=max_len,\n",
    "    dropout=0.1,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ccc74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7a6a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = LearningRateScheduler(d_model = 512)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc808c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5be9fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 정의\n",
    "#@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    # TODO: 구현    \n",
    "    tgt_in = tgt[:, :-1]\n",
    "    gold = tgt[:, 1:]\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02b26cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(sentence, model, tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    pieces = mecab.morphs(sentence)\n",
    "    tokens = tokenizer.texts_to_sequences(pieces)\n",
    "    \n",
    "    _input = pad_sequences(tokens, maxlen = enc_train.shape[-1], padding = 'post', value = 0)\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "            generate_masks(_input, output)\n",
    "        \n",
    "        predictions, _, _, _ = model(_input, \n",
    "                                     output,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        \n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis = -1)[0, -1]).numpy().item()\n",
    "        \n",
    "        if tokenizer.word_index['<end>'] == predicted_id:\n",
    "            result = [tokenizer.index_word[idx] for idx in ids]\n",
    "            result = \" \".join(result)\n",
    "            return result\n",
    "        \n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis = -1)\n",
    "        \n",
    "    result = \" \".join([tokenizer.index_word[idx] for idx in ids])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bdcfb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    '지루하다, 놀러가고 싶어.',\n",
    "    '오늘 일찍 일어났더니 피곤하다.',\n",
    "    '간만에 여자친구랑 데이트 하기로 했어.',\n",
    "    '집에 있는다는 소리야.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b26c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|██████████| 362/362 [02:00<00:00,  3.01it/s, Batch=362, Loss=4.78, Avg Loss=6.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 은 은 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 게 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 좋 좋 좋 좋 게 좋 좋 좋 좋 좋 좋 좋 좋 좋 좋 좋 좋 좋 좋 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 사랑 는 는 게 는 는 는 는 는 는 게 는 는 는 는 게 게 게 게 게 는 는 는 는 보 세요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 좋 좋 좋 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  1\n",
      "-------------------------------------------\n",
      "Epoch 1 completed. Average Loss: 6.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|██████████| 362/362 [02:00<00:00,  3.01it/s, Batch=362, Loss=3.66, Avg Loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 연락 이 연락 이 연락 이\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 좋 은 좋 은 좋 아 하 세요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 사랑 이 도 응원 할 수 도 있 어요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 은 좋 은 좋 은 좋 은 좋 은 좋 은 좋 은 좋 은 좋 은 좋 은 좋 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  2\n",
      "-------------------------------------------\n",
      "Epoch 2 completed. Average Loss: 4.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3: 100%|██████████| 362/362 [01:58<00:00,  3.05it/s, Batch=362, Loss=2.81, Avg Loss=3.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 그 사람 은 그 사람 이 요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 오늘 았 길 바랄게요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 꼬시 가 가 대로 응원 해 보 세요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 은 사람 이 최고 길 바랄게요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  3\n",
      "-------------------------------------------\n",
      "Epoch 3 completed. Average Loss: 3.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 4: 100%|██████████| 362/362 [01:58<00:00,  3.05it/s, Batch=362, Loss=2.14, Avg Loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 그 사람 으로 연락 하 는 게 좋 아 보 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 오늘 랑 안녕 !\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 사랑 도 사랑 도 사랑 도 몰랐 도 좋 아요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 무작정 할 수 없 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  4\n",
      "-------------------------------------------\n",
      "Epoch 4 completed. Average Loss: 2.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 5: 100%|██████████| 362/362 [02:16<00:00,  2.65it/s, Batch=362, Loss=1.31, Avg Loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 내 연락 이 내 말 이 내 내 요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 안녕 을 전해 보 세요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 별거 도 주 주 주 세요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 참 이 면 좋 으면 좋 으면 좋 으면 좋 으면 좋 으면 좋 은 것 같 은 것 같 습니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  5\n",
      "-------------------------------------------\n",
      "Epoch 5 completed. Average Loss: 1.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 6: 100%|██████████| 362/362 [01:58<00:00,  3.06it/s, Batch=362, Loss=0.867, Avg Loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 내 연락 연락 내 게 연락 내 는 게 연락 요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 많이 좋 아요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 가져가 는 게 몰랐 자체 도 몰랐 어요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 짧 으면 좋 으면 좋 길 바랍니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  6\n",
      "-------------------------------------------\n",
      "Epoch 6 completed. Average Loss: 1.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 7: 100%|██████████| 362/362 [01:57<00:00,  3.08it/s, Batch=362, Loss=0.615, Avg Loss=0.976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 좀 내 서 연락 해 보 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 잘 하 세요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 소중 도 도 도 좋 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 도 자체 도 도 도 도 도 도 도 도 도 도 도 도 도 도\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 은 정도 연락 해 보 길 바랍니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  7\n",
      "-------------------------------------------\n",
      "Epoch 7 completed. Average Loss: 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 8: 100%|██████████| 362/362 [01:57<00:00,  3.08it/s, Batch=362, Loss=0.57, Avg Loss=0.816] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 그 사람 이 좀 생각 해 보 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 잘 알아보 세요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 사랑 도 고생 했 어요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 부담 해도 되 면 좋 은 결정 이 있 으면 좋 겠 네요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  8\n",
      "-------------------------------------------\n",
      "Epoch 8 completed. Average Loss: 0.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 9: 100%|██████████| 362/362 [01:57<00:00,  3.08it/s, Batch=362, Loss=0.48, Avg Loss=0.71]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 그 사람 이 좀 더 연락 해 보 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 안녕 하 세요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 떨리 죠 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 으면 좋 으면 좋 , 나가 는 게 좋 을 것 같 아요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  9\n",
      "-------------------------------------------\n",
      "Epoch 9 completed. Average Loss: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 10: 100%|██████████| 362/362 [01:57<00:00,  3.09it/s, Batch=362, Loss=0.415, Avg Loss=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 좀 내 서 연락 해 보 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 잘 지내 길 늦 었 길 바랄게요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 사랑 했 다가 도 주 세요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 편하 고 오 고 집 나쁘 , 얼마나 나쁘 고 자 고 자 요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  10\n",
      "-------------------------------------------\n",
      "Epoch 10 completed. Average Loss: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 11: 100%|██████████| 362/362 [01:58<00:00,  3.05it/s, Batch=362, Loss=0.478, Avg Loss=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 그 사람 이 사 면 사 면 사 면 사 면 사 면 사 면 사 고 사 면 사 면 사 고 사 고 사 면 사 면 사 고 사 면 사 면 사 면 사 고 사\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 잘 하 길 기도 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 떨리 죠 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 길 고 좋 길 바랍니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  11\n",
      "-------------------------------------------\n",
      "Epoch 11 completed. Average Loss: 0.6115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 12: 100%|██████████| 362/362 [01:59<00:00,  3.04it/s, Batch=362, Loss=0.384, Avg Loss=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 짝사랑 앞 으로 짝사랑 내 나가 세요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 잘 버티 고 둘 이 네요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 고생 되 는 게 되 길 바랄게요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 은 선택 이 길 바랍니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  12\n",
      "-------------------------------------------\n",
      "Epoch 12 completed. Average Loss: 0.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 13: 100%|██████████| 362/362 [01:58<00:00,  3.06it/s, Batch=362, Loss=0.227, Avg Loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 같이 내 요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 오늘 강추위 래요 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 사 는 설레 도 좋 아요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 부담 되 지 마요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  13\n",
      "-------------------------------------------\n",
      "Epoch 13 completed. Average Loss: 0.4494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 14: 100%|██████████| 362/362 [01:57<00:00,  3.09it/s, Batch=362, Loss=0.168, Avg Loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 많이 만나 면 마음 이 내 나 봐요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 좋 은 소식 이 었 길 바랍니다 .\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 떨리 도 노력 입니다 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 생각 해도 준비 할 때 길 바랍니다 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  14\n",
      "-------------------------------------------\n",
      "Epoch 14 completed. Average Loss: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 15: 100%|██████████| 362/362 [01:57<00:00,  3.09it/s, Batch=362, Loss=0.256, Avg Loss=0.32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. 생각 이 좀 더 필요 할 거 예요 .\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. 안녕 !\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. 저 도 쉬 어도 노력 해요 .\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. 좋 은 선물 이 고 좋 을 때 좋 아요 .\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  6\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  15\n",
      "-------------------------------------------\n",
      "Epoch 15 completed. Average Loss: 0.3201\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(enumerate(train_dataset), total=dataset_count, desc = f\"EPOCH {epoch+1}\")\n",
    "\n",
    "    for batch, (src, tgt) in tqdm_bar:\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss.numpy()\n",
    "\n",
    "        tqdm_bar.set_postfix({\n",
    "            \"Batch\": batch + 1,\n",
    "            \"Loss\": loss.numpy(),\n",
    "            \"Avg Loss\": total_loss / (batch + 1)\n",
    "        })\n",
    "    \n",
    "    tqdm_bar.close()\n",
    "    \n",
    "    print(\"Generated Responses\")   \n",
    "    for idx, text in enumerate(sample_text):\n",
    "        \n",
    "        result = \\\n",
    "        generate_response(text, transformer, tokenizer)\n",
    "        \n",
    "        print(f\"> input : {idx+1}. {text}\")\n",
    "        print(f\"> output: {idx+1}. {result}\")\n",
    "        \n",
    "    print(\"\\nHyperparameters\")\n",
    "    print(\"n_layers: \", n_layers)\n",
    "    print(\"d_model: \", d_model)\n",
    "    print(\"n_heads: \", n_heads)\n",
    "    print(\"d_ff: \", d_ff)\n",
    "    print(\"dropout: \", dropout)\n",
    "        \n",
    "    print(\"\\nTraining Parameters\")\n",
    "    print(\"Warmup Steps: \", learning_rate.warmup_steps)\n",
    "    print(\"Batch Size: \", BATCH_SIZE)\n",
    "    print(\"Epoch At: \", epoch+1)\n",
    "    print(\"-------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {total_loss / dataset_count:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa02e53",
   "metadata": {},
   "source": [
    "## 5-1. 레이어 개수 변환하여 실험하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "468e6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|██████████| 362/362 [00:48<00:00,  7.54it/s, Batch=362, Loss=nan, Avg Loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  2\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  1\n",
      "-------------------------------------------\n",
      "Epoch 1 completed. Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|██████████| 362/362 [01:23<00:00,  4.36it/s, Batch=362, Loss=nan, Avg Loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Responses\n",
      "> input : 1. 지루하다, 놀러가고 싶어.\n",
      "> output: 1. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 2. 오늘 일찍 일어났더니 피곤하다.\n",
      "> output: 2. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 3. 간만에 여자친구랑 데이트 하기로 했어.\n",
      "> output: 3. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "> input : 4. 집에 있는다는 소리야.\n",
      "> output: 4. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Hyperparameters\n",
      "n_layers:  4\n",
      "d_model:  256\n",
      "n_heads:  8\n",
      "d_ff:  1024\n",
      "dropout:  0.1\n",
      "\n",
      "Training Parameters\n",
      "Warmup Steps:  4000\n",
      "Batch Size:  64\n",
      "Epoch At:  1\n",
      "-------------------------------------------\n",
      "Epoch 1 completed. Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1:   4%|▎         | 13/362 [00:04<01:59,  2.93it/s, Batch=13, Loss=nan, Avg Loss=nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132/2289853927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/2939494388.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(src, tgt, model, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/316502540.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/1294809943.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, dec_enc_mask, padding_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mdec_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/1469976893.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, dec_enc_mask, padding_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Q, K, V 순서에 주의하세요!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_dec_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/2383144956.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mWV_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         out, attention_weights = self.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     54\u001b[0m             WQ_splits, WK_splits, WV_splits, mask)\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_132/2383144956.py\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0md_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc \n",
    "\n",
    "n_layers_list = [2, 4, 6, 8]\n",
    "\n",
    "for layer_num in n_layers_list:\n",
    "    # 하이퍼 파라미터\n",
    "    n_layers = layer_num\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    d_ff = 1024\n",
    "    pos_len = max_len\n",
    "    dropout = 0.1\n",
    "    \n",
    "    # 모델 초기화\n",
    "    if 'transformer' in locals():\n",
    "        del transformer\n",
    "        gc.collect()\n",
    "\n",
    "    # Transformer 인스턴스 생성\n",
    "    transformer = Transformer(\n",
    "        n_layers=n_layers,\n",
    "        d_model=d_model,\n",
    "        n_heads=n_heads,\n",
    "        d_ff=d_ff,\n",
    "        src_vocab_size=vocab_size,\n",
    "        tgt_vocab_size=vocab_size,\n",
    "        pos_len=max_len,\n",
    "        dropout=0.1,\n",
    "        shared_fc=True,\n",
    "        shared_emb=True\n",
    "    )\n",
    "    \n",
    "    # learning rate & optimizer & loss 초기화\n",
    "    learning_rate = LearningRateScheduler(d_model=d_model)\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    "    )\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none'\n",
    "    )\n",
    "\n",
    "    # Train Step 강제 초기화\n",
    "    dummy_src = tf.zeros((1, max_len), dtype=tf.int32)\n",
    "    dummy_tgt = tf.zeros((1, max_len), dtype=tf.int32)\n",
    "    train_step(dummy_src, dummy_tgt, transformer, optimizer)\n",
    "    \n",
    "    \n",
    "    # 모델 학습\n",
    "    EPOCHS = 1\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "\n",
    "        dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "        tqdm_bar = tqdm(enumerate(train_dataset), total=dataset_count, desc=f\"EPOCH {epoch+1}\")\n",
    "\n",
    "        for batch, (src, tgt) in tqdm_bar:\n",
    "            loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "            total_loss += loss.numpy()\n",
    "\n",
    "            tqdm_bar.set_postfix({\n",
    "                \"Batch\": batch + 1,\n",
    "                \"Loss\": loss.numpy(),\n",
    "                \"Avg Loss\": total_loss / (batch + 1)\n",
    "            })\n",
    "\n",
    "        tqdm_bar.close()\n",
    "\n",
    "        print(\"Generated Responses\")   \n",
    "        for idx, text in enumerate(sample_text):\n",
    "\n",
    "            result = \\\n",
    "            generate_response(text, transformer, tokenizer)\n",
    "\n",
    "            print(f\"> input : {idx+1}. {text}\")\n",
    "            print(f\"> output: {idx+1}. {result}\")\n",
    "\n",
    "        print(\"\\nHyperparameters\")\n",
    "        print(\"n_layers: \", n_layers)\n",
    "        print(\"d_model: \", d_model)\n",
    "        print(\"n_heads: \", n_heads)\n",
    "        print(\"d_ff: \", d_ff)\n",
    "        print(\"dropout: \", dropout)\n",
    "\n",
    "        print(\"\\nTraining Parameters\")\n",
    "        print(\"Warmup Steps: \", learning_rate.warmup_steps)\n",
    "        print(\"Batch Size: \", BATCH_SIZE)\n",
    "        print(\"Epoch At: \", epoch+1)\n",
    "        print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed. Average Loss: {total_loss / dataset_count:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef168571",
   "metadata": {},
   "source": [
    "# 6. 성능 측정하기 \n",
    "- BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda29fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e66c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights = [0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference], candidate, weights = weights, smoothing_function = SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283000aa",
   "metadata": {},
   "source": [
    "# 7. 회고 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1f7fa",
   "metadata": {},
   "source": [
    "- Loss는 안정적으로 잘 떨어지는 모습이 보임\n",
    "- 에폭 초반부에는 무의미하게 반복되는 단어 or 조사가 많이 보임\n",
    "- 14 epoch 정도는 돌려야 어느정도 온전한(?) 문장을 만들어내는 듯 함\n",
    "- n_layers = 2 에서는 1 epoch이긴 하나 \\<pad>만 잔뜩 찍어내는 걸로 봐서는 마스킹 처리가 제대로 되지 않은 것 같다..? 어째서지..\n",
    "\n",
    "\n",
    "\\[필요 추가 실험]\n",
    "- layer 개수, dim_size 등 다양하게 돌려보기...\n",
    "- 왜 레이어 개수 관찰 실험에서는 Loss값이 Nan으로 찍힐까...?\n",
    "    - 마스킹 처리가 제대로 되지 않은 것과 연관이 있는건가?\n",
    "- BLEU 스코어 측정해보기 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
